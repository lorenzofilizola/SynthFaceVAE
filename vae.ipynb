{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6PMLiUAM7AS"
   },
   "source": [
    "# Variational AutoEncoder\n",
    "\n",
    "**Author:** [fchollet](https://twitter.com/fchollet)<br>\n",
    "**Date created:** 2020/05/03<br>\n",
    "**Last modified:** 2020/05/03<br>\n",
    "**Description:** Convolutional Variational AutoEncoder (VAE) trained on MNIST digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FH1oXqqM7AU"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ii81scn6M7AV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXGzlRFeM7AW"
   },
   "source": [
    "## Create a sampling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "I3P_ef1wM7AX"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXkwy2aKM7AY"
   },
   "source": [
    "## Build the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 512, 512, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 256, 256, 3)  84          ['encoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 128, 128, 8)  224         ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 64, 64, 16)   1168        ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 32, 32, 32)   4640        ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 16, 16, 64)   18496       ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 8, 8, 64)     36928       ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 4, 4, 128)    73856       ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2048)         0           ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          1049088     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 512)          262656      ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 512)          262656      ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " sampling (Sampling)            (None, 512)          0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,709,796\n",
      "Trainable params: 1,709,796\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_encoder(filters, latent_dim=512, input_shape=(512,512,3)):\n",
    "\n",
    "\n",
    "    input_image = layers.Input(shape=input_shape, name='encoder_input')\n",
    "\n",
    "    x = layers.Conv2D(filters[0], 3, (2, 2), padding='same', activation='leaky_relu')(input_image)\n",
    "\n",
    "    for n_filters in filters[1:]:\n",
    "        x = layers.Conv2D(n_filters, 3, (2, 2), padding='same', activation='leaky_relu')(x)\n",
    "\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    x = layers.Dense(latent_dim)(x)\n",
    "\n",
    "    z_mean = layers.Dense(latent_dim, name='z_mean')(x)\n",
    "    z_log_var = layers.Dense(latent_dim, name='z_log_var', kernel_initializer='zeros')(x)\n",
    "\n",
    "\n",
    "    # use the reparameterization trick and get the output from the sample() function\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "\n",
    "\n",
    "    return keras.Model(input_image, [z_mean, z_log_var, z], name='encoder')\n",
    "\n",
    "encoder_filters = [3, 8, 16, 32, 64, 64, 128]\n",
    "encoder = build_encoder(encoder_filters, latent_dim=512)\n",
    "encoder.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " z_sampling (InputLayer)     [(None, 512)]             0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 4, 4, 32)          0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 4, 4, 128)         36992     \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 8, 8, 128)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 8, 8, 64)          73792     \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSampling  (None, 32, 32, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 32, 32, 32)        18464     \n",
      "                                                                 \n",
      " up_sampling2d_3 (UpSampling  (None, 64, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 64, 64, 16)        4624      \n",
      "                                                                 \n",
      " up_sampling2d_4 (UpSampling  (None, 128, 128, 16)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 128, 128, 8)       1160      \n",
      "                                                                 \n",
      " up_sampling2d_5 (UpSampling  (None, 256, 256, 8)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 256, 256, 3)       219       \n",
      "                                                                 \n",
      " up_sampling2d_6 (UpSampling  (None, 512, 512, 3)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 172,179\n",
      "Trainable params: 172,179\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_decoder(filters, latent_dim=512, input_shape=(512,512,3)):\n",
    "    latent_input = layers.Input(shape=(latent_dim,), name='z_sampling')\n",
    "    #512/2^n where n is number of conv layers\n",
    "    x_dim = int(input_shape[0] / (2 ** len(filters)))\n",
    "    #dense_filters = latent_dim * 8\n",
    "    #x = layers.Dense(dense_filters, activation='relu')(latent_input)\n",
    "    x = layers.Reshape((x_dim, x_dim, int(latent_dim / x_dim**2)))(latent_input)\n",
    "\n",
    "    for n_filters in filters:\n",
    "        x = layers.Conv2D(n_filters, 3, (1, 1), padding='same', activation='tanh')(x)\n",
    "        x = layers.UpSampling2D()(x)\n",
    "\n",
    "    ##x = layers.Conv2DTranspose(3, (1, 1), (1, 1), padding='same', activation='sigmoid')(x)\n",
    "\n",
    "    return keras.Model(latent_input, x, name='decoder')\n",
    "\n",
    "\n",
    "decoder_filters = [128, 64, 64, 32, 16, 8, 3]\n",
    "decoder = build_decoder(decoder_filters, latent_dim=512)\n",
    "decoder.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnHBo3e4M7Aa"
   },
   "source": [
    "## Define the VAE as a `Model` with a custom `train_step`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "caPQZeDqM7Ab"
   },
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        z_mean, z_log_var, z = encoder(inputs)\n",
    "        return decoder(z)\n",
    "\n",
    "    def __init__(self, encoder, decoder, beta=1.0, loss='mse', **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.beta = beta\n",
    "        self.rec_loss = loss\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "        self.val_total_loss_tracker = keras.metrics.Mean(name=\"val_total_loss\")\n",
    "        self.val_reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"val_reconstruction_loss\"\n",
    "        )\n",
    "        self.val_kl_loss_tracker = keras.metrics.Mean(name=\"val_kl_loss\")\n",
    "\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = 0\n",
    "            if self.rec_loss == 'mse':\n",
    "                reconstruction_loss = tf.reduce_mean(\n",
    "                    tf.reduce_sum(\n",
    "                        keras.losses.mse(data, reconstruction), axis=(1,2)\n",
    "                    )\n",
    "                )\n",
    "            elif self.rec_loss == 'bce':\n",
    "                reconstruction_loss = tf.reduce_mean(\n",
    "                    tf.reduce_sum(\n",
    "                        keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                print(\"wrong loss {loss}\".format(loss=self.rec_loss))\n",
    "\n",
    "            kl_loss = -self.beta * 0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    def test_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            val_reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            val_kl_loss = -self.beta * 0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            val_kl_loss = tf.reduce_mean(tf.reduce_sum(val_kl_loss, axis=1))\n",
    "            val_total_loss = val_reconstruction_loss + val_kl_loss\n",
    "\n",
    "        self.val_total_loss_tracker.update_state(val_total_loss)\n",
    "        self.val_reconstruction_loss_tracker.update_state(val_reconstruction_loss)\n",
    "        self.val_kl_loss_tracker.update_state(val_kl_loss)\n",
    "        return {\n",
    "            \"total_loss\": self.val_total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.val_reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.val_kl_loss_tracker.result(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0gHo7vkM7Ac"
   },
   "source": [
    "## Train the VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Datasets\n"
     ]
    }
   ],
   "source": [
    "%cd \"C:\\Datasets\\\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "import splitfolders\n",
    "splitfolders.ratio('flickrfaces/dummy', output=\"flickrfaces/splits\", seed=1337, ratio=(.8, 0.1,0.1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "directory = \"flickrfaces\\splits\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    img = (img - 0.5) * 2\n",
    "    return img"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess,\n",
    "    #rescale=1./255,\n",
    "    #shear_range=0.2,\n",
    "    #zoom_range=0.2,\n",
    "    horizontal_flip=False, #True\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 56000 images belonging to 1 classes.\n",
      "Found 7000 images belonging to 1 classes.\n",
      "Found 7048 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "X_DIM = 512\n",
    "Y_DIM = 512\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        os.path.join(directory, 'train'),\n",
    "        target_size=(X_DIM, Y_DIM),\n",
    "        class_mode=None,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        seed=None,\n",
    "        )\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        os.path.join(directory, 'val'),\n",
    "        target_size=(X_DIM, Y_DIM),\n",
    "        class_mode=None,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        seed=None,\n",
    "        )\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "        os.path.join(directory, 'test'),\n",
    "        target_size=(X_DIM, Y_DIM),\n",
    "        class_mode=None,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        seed=None,\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "class VisualizeIOCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, log_dir):\n",
    "        super().__init__()\n",
    "        self.original_batch = validation_generator.next()\n",
    "        self.file_writer = tf.summary.create_file_writer(log_dir)\n",
    "        original_batch = self.original_batch / 2 + 0.5\n",
    "        with self.file_writer.as_default():\n",
    "            images = np.reshape(original_batch[0:8], (-1, 512, 512, 3))\n",
    "            tf.summary.image(\"8 training input examples\", images, max_outputs=8, step=0)\n",
    "\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        z_mean, z_log_var, z = encoder.predict(self.original_batch)\n",
    "        reconstructed = decoder.predict(z)\n",
    "        reconstructed = reconstructed / 2 + 0.5\n",
    "\n",
    "        # Using the file writer, log the reshaped image.\n",
    "        with self.file_writer.as_default():\n",
    "            images = np.reshape(reconstructed[0:8], (-1, 512, 512, 3))\n",
    "            tf.summary.image(\"8 training output examples\", images, max_outputs=8, step=epoch)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# Checkpoint\n",
    "checkpoint_path = \"D:/Notebooks/Advanced_DL/Checkpoint/\"\n",
    "\n",
    "#if not os.path.exists(checkpoint_path):\n",
    "#    os.makedirs(checkpoint_path)\n",
    "\n",
    "callbacks = []\n",
    "\n",
    "callbacks.append(keras.callbacks.ReduceLROnPlateau(monitor='loss',\n",
    "                                                   min_delta=50,\n",
    "                                                   patience=5))\n",
    "\n",
    "now_str = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "cp_callback = keras.callbacks.ModelCheckpoint(os.path.join(checkpoint_path, now_str + '.hdf5'),\n",
    "                              monitor='loss',\n",
    "                              save_best_only=True,\n",
    "                              save_weights_only=True,\n",
    "                              mode='auto',\n",
    "                              verbose=1)\n",
    "callbacks.append(cp_callback)\n",
    "\n",
    "log_dir = \"D:/Notebooks/Advanced_DL/logs/\" + now_str\n",
    "\n",
    "visualization_callback = VisualizeIOCallback(log_dir +\"/images\")\n",
    "callbacks.append(visualization_callback)\n",
    "\n",
    "callbacks.append(keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0))\n",
    "\n",
    "# Early Stopping\n",
    "EARLY_STOP = False\n",
    "if EARLY_STOP:\n",
    "    es_callback = keras.callbacks.EarlyStopping(monitor='val_total_loss',\n",
    "                                                   mode='auto',\n",
    "                                                   patience=10,\n",
    "                                                   verbose=1)\n",
    "    callbacks.append(es_callback)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "m-wUn41iM7Ac",
    "outputId": "6f9c2a84-001b-4e45-dcdb-20112fa6bf17",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/200\n",
      "438/438 [==============================] - ETA: 0s - loss: 11195.5671 - reconstruction_loss: 9793.0215 - kl_loss: 1027.1321\n",
      "Epoch 42: loss improved from inf to 10820.15430, saving model to D:/Notebooks/Advanced_DL/Checkpoint\\20221011-200545.hdf5\n",
      "4/4 [==============================] - 1s 54ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "438/438 [==============================] - 247s 548ms/step - loss: 11194.7119 - reconstruction_loss: 9793.0215 - kl_loss: 1027.1321 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "438/438 [==============================] - ETA: 0s - loss: 10697.2816 - reconstruction_loss: 9661.4443 - kl_loss: 1028.1958\n",
      "Epoch 43: loss improved from 10820.15430 to 10689.64453, saving model to D:/Notebooks/Advanced_DL/Checkpoint\\20221011-200545.hdf5\n",
      "4/4 [==============================] - 0s 57ms/step\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "438/438 [==============================] - 240s 540ms/step - loss: 10697.2642 - reconstruction_loss: 9661.4443 - kl_loss: 1028.1958 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "438/438 [==============================] - ETA: 0s - loss: 10675.1165 - reconstruction_loss: 9625.4199 - kl_loss: 1029.2085\n",
      "Epoch 44: loss improved from 10689.64453 to 10654.62402, saving model to D:/Notebooks/Advanced_DL/Checkpoint\\20221011-200545.hdf5\n",
      "4/4 [==============================] - 0s 52ms/step\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "438/438 [==============================] - 246s 550ms/step - loss: 10675.0698 - reconstruction_loss: 9625.4199 - kl_loss: 1029.2085 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "438/438 [==============================] - ETA: 0s - loss: 10604.9439 - reconstruction_loss: 9576.5264 - kl_loss: 1030.8633\n",
      "Epoch 45: loss improved from 10654.62402 to 10607.38672, saving model to D:/Notebooks/Advanced_DL/Checkpoint\\20221011-200545.hdf5\n",
      "4/4 [==============================] - 0s 47ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "438/438 [==============================] - 243s 545ms/step - loss: 10604.9495 - reconstruction_loss: 9576.5264 - kl_loss: 1030.8633 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "438/438 [==============================] - ETA: 0s - loss: 10599.3264 - reconstruction_loss: 9547.6436 - kl_loss: 1031.2675\n",
      "Epoch 46: loss improved from 10607.38672 to 10578.91016, saving model to D:/Notebooks/Advanced_DL/Checkpoint\\20221011-200545.hdf5\n",
      "4/4 [==============================] - 0s 52ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "438/438 [==============================] - 241s 538ms/step - loss: 10599.2799 - reconstruction_loss: 9547.6436 - kl_loss: 1031.2675 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "438/438 [==============================] - ETA: 0s - loss: 10556.7377 - reconstruction_loss: 9499.6523 - kl_loss: 1032.0981\n",
      "Epoch 47: loss improved from 10578.91016 to 10531.75195, saving model to D:/Notebooks/Advanced_DL/Checkpoint\\20221011-200545.hdf5\n",
      "4/4 [==============================] - 0s 54ms/step\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "438/438 [==============================] - 234s 527ms/step - loss: 10556.6808 - reconstruction_loss: 9499.6523 - kl_loss: 1032.0981 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "438/438 [==============================] - ETA: 0s - loss: 10533.9554 - reconstruction_loss: 9465.2676 - kl_loss: 1032.7097\n",
      "Epoch 48: loss improved from 10531.75195 to 10497.97266, saving model to D:/Notebooks/Advanced_DL/Checkpoint\\20221011-200545.hdf5\n",
      "4/4 [==============================] - 0s 50ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "438/438 [==============================] - 233s 522ms/step - loss: 10533.8734 - reconstruction_loss: 9465.2676 - kl_loss: 1032.7097 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "438/438 [==============================] - ETA: 0s - loss: 10447.9705 - reconstruction_loss: 9412.0391 - kl_loss: 1033.6444\n",
      "Epoch 49: loss improved from 10497.97266 to 10445.69629, saving model to D:/Notebooks/Advanced_DL/Checkpoint\\20221011-200545.hdf5\n",
      "4/4 [==============================] - 0s 48ms/step\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "438/438 [==============================] - 240s 540ms/step - loss: 10447.9653 - reconstruction_loss: 9412.0391 - kl_loss: 1033.6444 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "438/438 [==============================] - ETA: 0s - loss: 10439.5804 - reconstruction_loss: 9398.1904 - kl_loss: 1034.2891\n",
      "Epoch 50: loss improved from 10445.69629 to 10432.48047, saving model to D:/Notebooks/Advanced_DL/Checkpoint\\20221011-200545.hdf5\n",
      "4/4 [==============================] - 0s 52ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "438/438 [==============================] - 253s 569ms/step - loss: 10439.5642 - reconstruction_loss: 9398.1904 - kl_loss: 1034.2891 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "438/438 [==============================] - ETA: 0s - loss: 10373.9534 - reconstruction_loss: 9358.0928 - kl_loss: 1035.3732\n",
      "Epoch 51: loss improved from 10432.48047 to 10393.45801, saving model to D:/Notebooks/Advanced_DL/Checkpoint\\20221011-200545.hdf5\n",
      "4/4 [==============================] - 0s 46ms/step\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "438/438 [==============================] - 250s 559ms/step - loss: 10373.9978 - reconstruction_loss: 9358.0928 - kl_loss: 1035.3732 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "438/438 [==============================] - ETA: 0s - loss: 10369.2194 - reconstruction_loss: 9327.8662 - kl_loss: 1035.8561\n",
      "Epoch 52: loss improved from 10393.45801 to 10363.72559, saving model to D:/Notebooks/Advanced_DL/Checkpoint\\20221011-200545.hdf5\n",
      "4/4 [==============================] - 0s 62ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "438/438 [==============================] - 256s 574ms/step - loss: 10369.2069 - reconstruction_loss: 9327.8662 - kl_loss: 1035.8561 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "438/438 [==============================] - ETA: 0s - loss: 10321.4464 - reconstruction_loss: 9291.3115 - kl_loss: 1037.1877\n",
      "Epoch 53: loss improved from 10363.72559 to 10328.49316, saving model to D:/Notebooks/Advanced_DL/Checkpoint\\20221011-200545.hdf5\n",
      "4/4 [==============================] - 0s 58ms/step\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "438/438 [==============================] - 256s 573ms/step - loss: 10321.4625 - reconstruction_loss: 9291.3115 - kl_loss: 1037.1877 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "438/438 [==============================] - ETA: 0s - loss: 10360.2221 - reconstruction_loss: 9269.6611 - kl_loss: 1037.4246\n",
      "Epoch 54: loss improved from 10328.49316 to 10307.08594, saving model to D:/Notebooks/Advanced_DL/Checkpoint\\20221011-200545.hdf5\n",
      "4/4 [==============================] - 0s 52ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "438/438 [==============================] - 250s 562ms/step - loss: 10360.1011 - reconstruction_loss: 9269.6611 - kl_loss: 1037.4246 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "438/438 [==============================] - ETA: 0s - loss: 10288.8753 - reconstruction_loss: 9246.2168 - kl_loss: 1037.8619\n",
      "Epoch 55: loss improved from 10307.08594 to 10284.08105, saving model to D:/Notebooks/Advanced_DL/Checkpoint\\20221011-200545.hdf5\n",
      "4/4 [==============================] - 0s 56ms/step\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "438/438 [==============================] - 244s 546ms/step - loss: 10288.8644 - reconstruction_loss: 9246.2168 - kl_loss: 1037.8619 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "438/438 [==============================] - ETA: 0s - loss: 10200.7117 - reconstruction_loss: 9208.9170 - kl_loss: 1038.5219\n",
      "Epoch 56: loss improved from 10284.08105 to 10247.43652, saving model to D:/Notebooks/Advanced_DL/Checkpoint\\20221011-200545.hdf5\n",
      "4/4 [==============================] - 0s 50ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "438/438 [==============================] - 239s 535ms/step - loss: 10200.8181 - reconstruction_loss: 9208.9170 - kl_loss: 1038.5219 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "438/438 [==============================] - ETA: 0s - loss: 10222.2575 - reconstruction_loss: 9184.9180 - kl_loss: 1039.2089\n",
      "Epoch 57: loss improved from 10247.43652 to 10224.13379, saving model to D:/Notebooks/Advanced_DL/Checkpoint\\20221011-200545.hdf5\n",
      "4/4 [==============================] - 0s 58ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "438/438 [==============================] - 254s 567ms/step - loss: 10222.2618 - reconstruction_loss: 9184.9180 - kl_loss: 1039.2089 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "438/438 [==============================] - ETA: 0s - loss: 10181.8677 - reconstruction_loss: 9152.9326 - kl_loss: 1040.4668\n",
      "Epoch 58: loss improved from 10224.13379 to 10193.40430, saving model to D:/Notebooks/Advanced_DL/Checkpoint\\20221011-200545.hdf5\n",
      "4/4 [==============================] - 0s 54ms/step\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "438/438 [==============================] - 255s 570ms/step - loss: 10181.8940 - reconstruction_loss: 9152.9326 - kl_loss: 1040.4668 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "438/438 [==============================] - ETA: 0s - loss: 10143.9043 - reconstruction_loss: 9127.8193 - kl_loss: 1040.4386\n",
      "Epoch 59: loss improved from 10193.40430 to 10168.25000, saving model to D:/Notebooks/Advanced_DL/Checkpoint\\20221011-200545.hdf5\n",
      "4/4 [==============================] - 0s 47ms/step\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "438/438 [==============================] - 250s 561ms/step - loss: 10143.9598 - reconstruction_loss: 9127.8193 - kl_loss: 1040.4386 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "438/438 [==============================] - ETA: 0s - loss: 10171.9903 - reconstruction_loss: 9108.4619 - kl_loss: 1041.3815\n",
      "Epoch 60: loss improved from 10168.25000 to 10149.84961, saving model to D:/Notebooks/Advanced_DL/Checkpoint\\20221011-200545.hdf5\n",
      "4/4 [==============================] - 0s 47ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "438/438 [==============================] - 242s 540ms/step - loss: 10171.9398 - reconstruction_loss: 9108.4619 - kl_loss: 1041.3815 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "438/438 [==============================] - ETA: 0s - loss: 10119.8718 - reconstruction_loss: 9078.5332 - kl_loss: 1041.9617\n",
      "Epoch 61: loss improved from 10149.84961 to 10120.49121, saving model to D:/Notebooks/Advanced_DL/Checkpoint\\20221011-200545.hdf5\n",
      "4/4 [==============================] - 0s 47ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "438/438 [==============================] - 245s 547ms/step - loss: 10119.8732 - reconstruction_loss: 9078.5332 - kl_loss: 1041.9617 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "438/438 [==============================] - ETA: 0s - loss: 10092.6363 - reconstruction_loss: 9068.8662 - kl_loss: 1042.3215\n",
      "Epoch 62: loss improved from 10120.49121 to 10111.18945, saving model to D:/Notebooks/Advanced_DL/Checkpoint\\20221011-200545.hdf5\n",
      "4/4 [==============================] - 0s 47ms/step\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "438/438 [==============================] - 239s 534ms/step - loss: 10092.6786 - reconstruction_loss: 9068.8662 - kl_loss: 1042.3215 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "438/438 [==============================] - ETA: 0s - loss: 10090.9405 - reconstruction_loss: 9034.4492 - kl_loss: 1043.4762\n",
      "Epoch 63: loss improved from 10111.18945 to 10077.92676, saving model to D:/Notebooks/Advanced_DL/Checkpoint\\20221011-200545.hdf5\n",
      "4/4 [==============================] - 0s 47ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "438/438 [==============================] - 233s 524ms/step - loss: 10090.9109 - reconstruction_loss: 9034.4492 - kl_loss: 1043.4762 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "438/438 [==============================] - ETA: 0s - loss: 10072.9870 - reconstruction_loss: 9020.2734 - kl_loss: 1043.7772\n",
      "Epoch 64: loss improved from 10077.92676 to 10064.04980, saving model to D:/Notebooks/Advanced_DL/Checkpoint\\20221011-200545.hdf5\n",
      "4/4 [==============================] - 0s 47ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "438/438 [==============================] - 235s 526ms/step - loss: 10072.9667 - reconstruction_loss: 9020.2734 - kl_loss: 1043.7772 - lr: 0.0010\n",
      "Epoch 65/200\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'Mean' defined at (most recent call last):\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\loren\\AppData\\Local\\Temp\\ipykernel_10396\\541913300.py\", line 9, in <cell line: 9>\n      results = vae.fit(train_generator,\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\loren\\AppData\\Local\\Temp\\ipykernel_10396\\3340400612.py\", line 42, in train_step\n      keras.losses.mse(data, reconstruction), axis=(1,2)\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\losses.py\", line 1486, in mean_squared_error\n      return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend.py\", line 2915, in mean\n      return tf.reduce_mean(x, axis, keepdims)\nNode: 'Mean'\nOOM when allocating tensor with shape[33554432] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node Mean}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_3382]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mResourceExhaustedError\u001B[0m                    Traceback (most recent call last)",
      "Input \u001B[1;32mIn [14]\u001B[0m, in \u001B[0;36m<cell line: 9>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      5\u001B[0m opt \u001B[38;5;241m=\u001B[39m keras\u001B[38;5;241m.\u001B[39moptimizers\u001B[38;5;241m.\u001B[39mRMSprop(learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-3\u001B[39m)\n\u001B[0;32m      7\u001B[0m vae\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39mopt, loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m----> 9\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mvae\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m200\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m                  \u001B[49m\u001B[38;5;66;43;03m#validation_data=validation_generator,\u001B[39;49;00m\n\u001B[0;32m     13\u001B[0m \u001B[43m                  \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m41\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m8\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m                  \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[0;32m     55\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mResourceExhaustedError\u001B[0m: Graph execution error:\n\nDetected at node 'Mean' defined at (most recent call last):\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\loren\\AppData\\Local\\Temp\\ipykernel_10396\\541913300.py\", line 9, in <cell line: 9>\n      results = vae.fit(train_generator,\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\loren\\AppData\\Local\\Temp\\ipykernel_10396\\3340400612.py\", line 42, in train_step\n      keras.losses.mse(data, reconstruction), axis=(1,2)\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\losses.py\", line 1486, in mean_squared_error\n      return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n    File \"C:\\Users\\loren\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend.py\", line 2915, in mean\n      return tf.reduce_mean(x, axis, keepdims)\nNode: 'Mean'\nOOM when allocating tensor with shape[33554432] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node Mean}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_3382]"
     ]
    }
   ],
   "source": [
    "vae = VAE(encoder, decoder, beta=1)\n",
    "vae(train_generator.next())\n",
    "latest_checkpoint = \"20221011-200545\"\n",
    "vae.load_weights(\"D:/Notebooks/Advanced_DL/Checkpoint/\" + latest_checkpoint + \".hdf5\")\n",
    "#opt = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "opt = keras.optimizers.RMSprop(learning_rate=1e-3)\n",
    "\n",
    "vae.compile(optimizer=opt, loss=None)\n",
    "\n",
    "results = vae.fit(train_generator,\n",
    "                  epochs=200,\n",
    "                  callbacks = callbacks,\n",
    "                  #validation_data=validation_generator,\n",
    "                  initial_epoch=41,\n",
    "                  workers=8,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 99s 2s/step - total_loss: -1086551.8750 - reconstruction_loss: -1087593.6250 - kl_loss: 1041.9170\n"
     ]
    },
    {
     "data": {
      "text/plain": "[-1086551.875, -1087593.625, 1041.9169921875]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.evaluate(validation_generator)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "vae",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
